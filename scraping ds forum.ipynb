{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import json\n",
    "from time import sleep, perf_counter as pf\n",
    "import re\n",
    "\n",
    "def raze_list(l):\n",
    "    out = []\n",
    "    for x in l:\n",
    "        if type(x) == list:\n",
    "            out += raze_list(x)\n",
    "        else:\n",
    "            out.append(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are starting our web scraping at the main forum of [Data Science Central](https://www.datasciencecentral.com/) to search for technologies and languages as well as social media and employment sites being discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_link = 'https://www.datasciencecentral.com/forum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_with_link(tag):\n",
    "    return (tag.name == 'p' or tag.name == 'h3') and tag.find('a') is not None\n",
    "def get_link(tag):\n",
    "    return tag.name == 'a' and tag.has_attr('href')\n",
    "def get_next(tag):\n",
    "    return tag.name == 'a' and tag.has_attr('href') and 'next' in tag.text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "links = []\n",
    "while next_link is not None and i < 50:\n",
    "    r = requests.get(next_link)\n",
    "    page = BeautifulSoup(r.text, 'html.parser')\n",
    "    tmp = raze_list([list(x.find('tbody').find_all('tr')) for x in page.find_all('table', attrs={'class':'categories'}) \\\n",
    "                      if x.find('tbody') is not None])\n",
    "    links += [x.find(p_with_link).find(get_link)['href'] for x in tmp if x.find(p_with_link) is not None]\n",
    "\n",
    "    tmp = page.find('ul', attrs={'class':'pagination easyclear '})\n",
    "    if tmp is not None:\n",
    "        tmp = tmp.find(get_next)\n",
    "        if tmp is not None:\n",
    "            next_link = tmp['href']\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of posts analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for link in links:\n",
    "    page = BeautifulSoup(requests.get(link).text, 'html.parser')\n",
    "    for script in page([\"script\", \"style\"]):\n",
    "        script.decompose()   \n",
    "    text += page.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of the languages and technologies and the frequencies with which they were mentioned in the forum.  It should be noted that the forum specializes in big data, and the website proper specifically mentions Hadoop, so its popularity in discussion is unsurprising.  Alongside are the regular expressions used to match the keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python': (re.compile(r'python', re.UNICODE), 439),\n",
       " 'r': (re.compile(r'\\br\\b', re.UNICODE), 463),\n",
       " 'sql': (re.compile(r'sql', re.UNICODE), 152),\n",
       " 'sas': (re.compile(r'\\bsas\\b|statistical analysis system', re.UNICODE), 76),\n",
       " 'excel': (re.compile(r'\\bexcel\\b', re.UNICODE), 90),\n",
       " 'spss': (re.compile(r'spss|statistical package for (the ){0,1}social science',\n",
       "  re.UNICODE),\n",
       "  6),\n",
       " 'hadoop': (re.compile(r'hadoop', re.UNICODE), 780),\n",
       " 'kibana': (re.compile(r'kibana', re.UNICODE), 1),\n",
       " 'tableau': (re.compile(r'tableau', re.UNICODE), 22),\n",
       " 'pig': (re.compile(r'pig', re.UNICODE), 22),\n",
       " 'stata': (re.compile(r'\\bstata\\b', re.UNICODE), 1),\n",
       " 'powerbi': (re.compile(r'power bi', re.UNICODE), 4),\n",
       " 'java': (re.compile(r'java', re.UNICODE), 685),\n",
       " 'c/c++': (re.compile(r'\\bc(\\+\\+){0,1}\\b', re.UNICODE), 178),\n",
       " 'hive': (re.compile(r'hive', re.UNICODE), 49),\n",
       " 'matlab': (re.compile(r'matlab', re.UNICODE), 22),\n",
       " 'ruby': (re.compile(r'ruby', re.UNICODE), 5),\n",
       " 'perl': (re.compile(r'perl', re.UNICODE), 49),\n",
       " 'hbase': (re.compile(r'hbase', re.UNICODE), 9),\n",
       " 'spark': (re.compile(r'spark', re.UNICODE), 29),\n",
       " 'php': (re.compile(r'\\bphp\\b', re.UNICODE), 7),\n",
       " 'scala': (re.compile(r'\\bscala\\b', re.UNICODE), 27),\n",
       " 'tensorflow': (re.compile(r'tensor( ){0,1}flow', re.UNICODE), 8),\n",
       " 'pytorch': (re.compile(r'py( ){0,1}torch', re.UNICODE), 0)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang = {'python':re.compile('python'), 'r': re.compile('\\\\br\\\\b'), 'sql':re.compile('sql'),\\\n",
    "       'sas':re.compile('\\\\bsas\\\\b|statistical analysis system'), 'excel': re.compile('\\\\bexcel\\\\b'), \\\n",
    "        'spss':re.compile('spss|statistical package for (the ){0,1}social science'), \\\n",
    "       'hadoop':re.compile('hadoop'), 'kibana':re.compile('kibana'), 'tableau':re.compile('tableau'), \\\n",
    "       'pig':re.compile('pig'), 'stata':re.compile('\\\\bstata\\\\b'), 'powerbi':re.compile('power bi'), \\\n",
    "       'java':re.compile('java'), 'c/c++':re.compile('\\\\bc(\\\\+\\\\+){0,1}\\\\b'), 'hive':re.compile('hive'), \\\n",
    "       'matlab':re.compile('matlab'), 'ruby':re.compile('ruby'), 'perl':re.compile('perl'), 'hbase':re.compile('hbase'), \\\n",
    "       'spark':re.compile('spark'), 'php':re.compile('\\\\bphp\\\\b'), 'scala':re.compile('\\\\bscala\\\\b'), \\\n",
    "        'tensorflow':re.compile('tensor( ){0,1}flow'), 'pytorch':re.compile('py( ){0,1}torch')}\n",
    "\n",
    "text = text.lower()\n",
    "\n",
    "for key in lang:\n",
    "    lang[key] = (lang[key], len(re.findall(lang[key], text)))\n",
    "    \n",
    "lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of the social media and employement sites mentioned in the forum alongside their frequency and the regular expression they matched.  It should be noted that each post contains buttons to link to Facebook, Twitter, and Google+ (not analysed), so their relatively high frequency should not be given much weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linkedin': (re.compile(r'linked( ){0,1}in', re.UNICODE), 43),\n",
       " 'facebook': (re.compile(r'facebook', re.UNICODE), 538),\n",
       " 'indeed': (re.compile(r'indeed', re.UNICODE), 35),\n",
       " 'glassdoor': (re.compile(r'glass( ){0,1}door', re.UNICODE), 2),\n",
       " 'monster': (re.compile(r'monster', re.UNICODE), 1),\n",
       " 'workopolis': (re.compile(r'workopolis', re.UNICODE), 0),\n",
       " 'twitter': (re.compile(r'twitter|tweet', re.UNICODE), 619),\n",
       " 'kijiji': (re.compile(r'kijiji', re.UNICODE), 0),\n",
       " 'craigslist': (re.compile(r\"craig'{0,1}s {0,1}list\", re.UNICODE), 1)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_media = {'linkedin':re.compile('linked( ){0,1}in'), 'facebook':re.compile('facebook'), \\\n",
    "               'indeed':re.compile('indeed'), 'glassdoor':re.compile('glass( ){0,1}door'), \\\n",
    "               'monster':re.compile('monster'), 'workopolis':re.compile('workopolis'), \\\n",
    "               'twitter':re.compile('twitter|tweet'), \\\n",
    "               'kijiji':re.compile('kijiji'), 'craigslist':re.compile(\"craig'{0,1}s {0,1}list\")}\n",
    "\n",
    "text = text.lower()\n",
    "\n",
    "for key in social_media:\n",
    "    social_media[key] = (social_media[key], len(re.findall(social_media[key], text)))\n",
    "    \n",
    "social_media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_lang = [(key,lang[key][1]) for key in lang]\n",
    "out_sm = [(key,social_media[key][1]) for key in social_media]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_lang = pd.DataFrame(out_lang, columns = ['lang', 'freq'])\n",
    "out_lang.to_csv('dsf_lang.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sm = pd.DataFrame(out_sm, columns = ['site', 'freq'])\n",
    "out_sm.to_csv('dsf_sm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
